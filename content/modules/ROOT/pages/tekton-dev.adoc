= OpenShift Pipelines - Development
:source-highlighter: rouge
:toc: macro
:toclevels: 1

== Learning Objectives

By the end of this section, you will:

* Access Red Hat Developer Hub and understand its value proposition
* Create a new secure Quarkus application using OpenShift Pipelines templates
* Experience self-service development that eliminates weeks of setup time
* Understand how security is built into the development process from day one

== Your Development Challenge

As ACME's newest developer, you're facing the same frustration that developers everywhere experience when trying to create modern Kubernetes-native applications:

=== Your Current Reality: Weeks of Waiting

The traditional development environment creates frustrating delays and dependencies. You submit tickets and then wait 3-5 business days for the platform team to set up your Kubernetes resources, watching your sprint plans slip. Another 1-2 weeks disappears in back-and-forth emails trying to get OpenShift Pipelines configured correctly, with miscommunications and competing priorities causing repeated delays. Multiple handoff meetings consume time as you, the platform team, and security try to align on requirements, each meeting adding days to your timeline. Security integration feels like black magic - complex requirements you don't fully understand but somehow need to implement correctly. Manual setup of GitOps repositories and deployment manifests makes every new project feel like starting from scratch, with no reusable templates or patterns to accelerate the process.

=== What This Really Costs You

The hidden costs accumulate across your organization and career. You personally spend more time in coordination meetings than writing code, which frustrates you and slows feature delivery. Platform teams become overwhelmed with setup requests and can't respond quickly, creating a bottleneck that affects every team. Security integration remains mysterious knowledge that only senior developers understand, creating dependencies and knowledge silos. Every new project feels like reinventing the wheel because there are no standardized templates or automated processes to reuse, wasting time solving the same problems repeatedly.

=== Your New Reality with RHADS: Self-Service in Minutes

RHADS transforms your development experience through four fundamental changes that eliminate traditional friction. Waiting time drops to zero as you create GitLab repositories and OpenShift Pipelines instantly through self-service, with no tickets and no coordination overhead. Configuration complexity disappears as Kubernetes resources generate automatically from templates, letting you focus on application code rather than infrastructure plumbing. Security gaps close automatically through container scanning and signing that happen transparently in your pipeline, making security invisible rather than obstructive. Platform team dependency evaporates as you become self-sufficient, gaining immediate productivity without waiting for others.

image::tekton-dev-aiimage-1.png[]

=== What This Means for Your Daily Work

* OpenShift Pipelines project setup: 3-4 weeks → 5 minutes
* Pipeline configuration: Manual meetings → Self-service automation
* Security compliance: 100% consistent without you needing to become a security expert
* Your productivity: Immediate access to everything you need

[IMPORTANT]
====
Today you'll experience this transformation firsthand by creating a production-ready application with OpenShift Pipelines in minutes, not weeks* You'll be amazed at how empowering this feels!
====

== Activity 1: Your First Steps into Your OpenShift Pipelines Journey

Let's embark on your journey by logging into your new development environment* You're about to discover how different OpenShift Pipelines makes your development experience!

=== Step 1: Open Red Hat Developer Hub

* Excited to explore your new tools, you navigate to the Red Hat Developer Hub using the URL from your welcome email:
+
link:{rhdh_url}[*Red Hat Developer Hub*^]

* You see the "Select a sign-in method" screen and click the *OIDC* option to start your journey

image::tekton-dev-1.png[link=self, window=_blank]

[TIP]
====
Your organization uses OIDC authentication powered by Red Hat build of Keycloak - this secure authentication integration will save you time throughout your development workflow.
====

=== Step 2: Enter Your Credentials

* You're presented with the Red Hat Trusted Artifact Signer login form with username and password fields

* You enter your lab credentials that were provided to you:
+
[source,bash,subs="attributes"]
----
Username: {rhdh_user}
Password: {rhdh_user_password}
----

* Click the blue *Sign In* button to proceed

[IMPORTANT]
====
If you encounter any authentication issues, you can always reference the "Lab Access Information" page for your credentials.
====

=== What You Just Discovered

You've just accessed something revolutionary - your organization's **Internal Developer Portal (IDP)** that's been optimized specifically for developers like you. The platform provides everything you've been wishing for: self-service application templates that eliminate waiting for platform teams to configure things manually, integrated Kubernetes and OpenShift resources that "just work" without deep infrastructure knowledge, automated pipeline creation that handles the complex security and compliance requirements for you, and a streamlined onboarding experience that gets you productive immediately rather than after weeks of setup.

"This is going to change everything," you think to yourself as you explore the interface.

== Activity 2: Creating Your First OpenShift Pipelines Application

Now comes the exciting part - you're about to experience the magic of self-service application creation with OpenShift Pipelines that will transform how you work!

=== Step 1: Discovering Software Templates

* Eager to get started on your Black Friday project, you spot the **+ Self-service** button in the top-right corner of the Developer Hub
* You click **+ Self-service** and are amazed to see a catalog of ready-to-use templates - no more starting from scratch!

image::tekton-dev-2.png[link=self, window=_blank]

=== Step 2: Choosing Your OpenShift Pipelines Template

* As you browse through the available templates, one catches your eye:
+
`*Securing a Quarkus Service Software Supply Chain (Tekton)*`

* "Perfect!" you think, "This is exactly what I need for a modern application with OpenShift Pipelines"
* You click *Choose* to select this template, excited to see what happens next

image::tekton-dev-3.png[link=self, window=_blank]

[TIP]
====
You're about to witness something amazing - this single template will automatically create your complete OpenShift Pipelines environment with Tekton workflows, Kubernetes resources, and security scanning* No tickets, no waiting, no manual configuration!
====

=== Step 3: Configure Your OpenShift Pipelines Application

The template form will guide you through OpenShift Pipelines configuration with three main sections:

==== Application Information

Ensure that the following values are set for your template values:

[cols="1,2", options="header"]
|===
| Field | Default Value
| Name | `qrks-tkn-{user}`
| Group ID | `redhat.rhdh`
| Artifact ID | `qrks-tkn-{user}`
| Java Package Name | `org.redhat.rhdh`
| Description | `A cool OpenShift Pipelines Quarkus app`
|===

Click *Next* to continue.

==== Image Registry Information

These settings determine where your OpenShift Pipelines container images will be stored:

[cols="1,2", options="header"]
|===
| Field | Default Value
| Image Registry | `Quay`
| Organization | `tssc`
|===

Click *Next* to continue.

==== Repository Information

This configures your OpenShift Pipelines source code repository and Tekton integration:

[cols="1,2", options="header"]
|===
| Field | Default Value
| Source Repo | `GitLab`
| Repo Owner | `development`
| Verify Commits | `enabled`
|===

Note that **Verify Commits** is enabled - this ensures all code commits are cryptographically signed for OpenShift Pipelines security.

Click *Review* to see a summary of your OpenShift Pipelines configuration.

=== Step 4: Create Your OpenShift Pipelines Application

* Review all the settings in the summary page

image::tekton-dev-4.png[link=self, window=_blank]

image::tekton-dev-5.png[link=self, window=_blank]

* Click *Create* to generate your OpenShift Pipelines application

The OpenShift Pipelines software template will now:

* Create GitLab repositories for your source code and GitOps manifests
* Set up Tekton pipelines with automated security scanning
* Configure Kubernetes resources for your application
* Set up container image signing and verification
* Deploy the OpenShift Pipelines application infrastructure to OpenShift

[TIP]
====
This entire OpenShift Pipelines setup that traditionally takes weeks is completed in under a minute!
====

=== Step 5: Access Your New OpenShift Pipelines Component

* Once the template execution completes, click *Open Component in Catalog*

* In Red Hat Developer Hub, go to the *Catalog* and locate your new component (`qrks-tkn-{user}`)

image::tekton-dev-6.png[link=self, window=_blank]

* Click the component name to open its *Overview* page

image::tekton-dev-7.png[link=self, window=_blank]

* You'll see your new OpenShift Pipelines application component with links to:
  * Source code repository with Kubernetes manifests
* Tekton CI/CD pipelines
* Application overview and health status
* OpenShift Dev Spaces development environment

== Activity 3: Understanding the Generated Repository Structure

=== Step 1: Exploring the Developer Hub Configuration

The template you just used is part of a sophisticated system with three key repositories:

**Developer Hub Configuration Repository:**

Location: `{gitlab_url}/rhdh/tssc-developer-hub-configuration[^]`

This repository contains the self-service template you just used (`scaffolder-templates/quarkus-stssc-template/`). The template defines what gets generated when you click "Create" in Developer Hub: application code structure, pipeline files, GitOps repo, and Dev Spaces workspace configuration.

**Your Generated Application Repository:**

Location: `{gitlab_url}/development/qrks-tkn-{user}[^]`

This repository contains your application source code plus the `.tekton/` directory with three pipeline definitions:

- `on-push.yaml` - Triggered by `git push` (builds and deploys to dev)
- `on-tag.yaml` - Triggered by `git tag` (promotes to staging)
- `on-release.yaml` - Triggered by GitLab Release (promotes to production)

=== Understanding Pipeline as Code

**What is Pipeline as Code?**

Pipeline as Code means your CI/CD pipeline definitions live alongside your application code in the same Git repository* This is revolutionary because:

* **Version Control**: Pipeline changes are tracked with your code changes
* **Reproducibility**: Anyone can see exactly how your application is built and deployed
* **Consistency**: The same pipeline runs regardless of environment
* **Developer Ownership**: Developers control their own pipeline without platform team dependencies

**Tekton Pipeline Files:**

Your `.tekton/` directory contains three pipeline definitions that trigger automatically:

[cols="2,2,4"]
|===
| File | Trigger | What it does

| `on-push.yaml`
| `git push`
| Builds and signs image → generates SBOM and attests image → scans for CVEs → deploys to dev environment

| `on-tag.yaml`
| `git tag v1.0 && git push --tags`
| Validates with Enterprise Contract → promotes to staging environment

| `on-release.yaml`
| Create GitLab Release
| Final validation → promotes to production environment
|===

Each pipeline is a Tekton `PipelineRun` resource that OpenShift Pipelines executes as Kubernetes pods.

**Why This Matters for You:**

* **No More Tickets**: Change your pipeline by editing YAML, not filing platform tickets
* **Full Transparency**: See exactly what happens when you deploy
* **Environment Consistency**: Same pipeline logic across dev, staging, production
* **Audit Trail**: Every pipeline change is tracked in Git history

**Pipeline Definitions Repository:**

Location: `{gitlab_url}/rhdh/tssc-sample-pipelines[^]`

This repository contains reusable Tekton task and pipeline definitions that your application pipelines reference:

- `tasks/` - Individual steps (e.g., `buildah-rhtap.yaml`, `acs-image-scan.yaml`)
- `pipelines/` - Complete workflows composed of tasks

When the platform team improves a task (e.g., better CVE scanning), all applications using that task benefit automatically.

**GitOps Repository:**

Location: `{gitlab_url}/development/qrks-tkn-{user}-gitops[^]`

This repository contains Kubernetes manifests that define your application deployments. OpenShift GitOps (ArgoCD) monitors this repo and automatically applies changes to your clusters when manifests are updated.

== Activity 4: Examining Your Pipeline as Code Files

=== Step 1: Viewing Your Pipeline Definitions

Now that you understand the concept, let's look at the actual pipeline files that were generated for you:

Navigate to your repository and open the `.tekton/` directory. You'll see three pipeline files:

**Pipeline file details:**

[cols="2,5"]
|===
| File | Pipeline tasks included

| `.tekton/on-push.yaml`
| `init` → `clone-repository` → `verify-commit` → `package` → `build-container` → `sign-and-attest` → `upload-sboms` + `update-deployment` (parallel) → `acs-image-check` + `acs-image-scan` + `acs-deploy-check` (parallel) → `show-sbom` + `summary`

| `.tekton/on-tag.yaml`
| `extract-tag` → `gather-images` → `verify-enterprise-contract` → `copy-image` → `update-deployment`

| `.tekton/on-release.yaml`
| `gather-images` → `verify-enterprise-contract` → `update-image-tag-prod` → `deploy-to-prod`
|===

**Key point:** These YAML files reference shared task definitions in `{gitlab_url}/rhdh/tssc-sample-pipelines[^]`. When the platform team improves a task (e.g., better CVE scanning), all projects using that task benefit automatically.

TIP: You can view the actual Tekton task definitions in the shared pipeline repo to understand exactly what each step does.

== Activity 5: Exploring Your New OpenShift Pipelines Development Environment

=== Step 1: Accessing Your Browser-Based IDE

* Back in your component overview, you notice a link for *OpenShift Dev Spaces* and click it curiously
* "A browser-based development environment?" you wonder, "This should be interesting..."

* If you're redirected to an authentication page, you click *Log in with OpenShift*

image::tekton-dev-8.png[link=self, window=_blank]

* On the *Authorize Access* screen, you click *Allow selected permissions*

image::tekton-dev-9.png[link=self, window=_blank]

* On the repository trust prompt, you click the checkbox and then click *Continue*

image::tekton-dev-10.png[link=self, window=_blank]

* When prompted to authenticate with GitLab, you enter your credentials:
+
[source,bash,subs="attributes"]
----
Username: {gitlab_user}
Password: {gitlab_user_password}
----

image::tekton-dev-11.png[link=self, window=_blank]

* Click *Authorize devspaces* on the next window

image::tekton-dev-12.png[link=self, window=_blank]

* Wait for the workspace to start and fully load VS Code
* If prompted, trust all workspaces and authors

image::tekton-dev-13.png[link=self, window=_blank]

* You sign in with the same credentials you've been using:
+
[source,bash,subs="attributes"]
----
Username: {rhdh_user}
Password: {rhdh_user_password}
----

* When prompted, you click *Allow selected permissions* to grant access to your development workspace

=== Step 2: Explore the OpenShift Pipelines Development Environment

Once your workspace loads, you'll see:

* **Pre-configured Quarkus project** with OpenShift Pipelines best practices
* **Kubernetes manifests** in the `/deploy` directory
* **Tekton pipeline definitions** showing your OpenShift Pipelines workflow
* **Container configuration** with security scanning integration

=== Step 3: Making Your First Code Change

Time to make your mark on the Black Friday project! Let's trigger your first automated pipeline:

* You expand the `docs` folder in the file explorer, feeling confident about diving into the code
* You open the `index.md` file and decide to document your modern setup
* You add this line at the end of the document, proud of what you're building:
+
[source,markdown]
----
This application uses OpenShift Pipelines (Tekton) for secure CI/CD.
----

* You save the file (Ctrl+S or Cmd+S), ready to see the magic happen

=== Step 4: Your First Signed Commit

* You open a terminal in Dev Spaces (*Terminal → New Terminal*) - no need to install anything locally!
* You stage your changes, feeling the anticipation build:
+
[source,bash]
----
git add .
----

* You commit your changes with confidence:
+
[source,bash]
----
git commit -m "Add OpenShift Pipelines documentation"
----
+
image::tekton-dev-15.png[link=self, window=_blank]

**What's happening now?** You're prompted for signed commit authentication. The terminal shows a URL - this is an OAuth flow to verify your identity.

**Why?** Your organization requires cryptographic proof of who made each commit.

**Who's signing?** You are using **gitsign** and **Red Hat Trusted Artifact Signer** (based on Sigstore).

Next steps:

* You click the URL directly in the terminal, or copy and paste it into a new browser window
* If prompted for credentials, you enter your RHDH credentials to prove your identity:
+
[source,bash,subs="attributes"]
----
Username: {rhdh_user}
Password: {rhdh_user_password}
----

* Once successfully authenticated in the browser, a verification code appears on the screen
+
image::tekton-dev-16.png[link=self, window=_blank]

* You copy this verification code from the browser
* You return to the terminal and paste the verification code when prompted
* **Result:** Your commit now has unforgeable cryptographic proof it came from you

* You push your changes to trigger the pipeline:
+
[source,bash]
----
git push
----

[TIP]
====
**What You Just Did: Supply Chain Security in Action**

Traditional Git commits can be forged - anyone can pretend to be you by setting `git config user.name "YourName"`. Your signed commit is different:

✓ **Proves your verified identity** made this change
✓ **Can't be tampered with or forged** by attackers
✓ **Provides audit trails** for compliance (SOC 2, PCI)
✓ **Builds trust** throughout your software supply chain

**The Technical Flow:**

1. You ran `git commit` → Git invoked **gitsign**
2. Gitsign requested authentication → Browser OAuth flow opened
3. You verified your identity → **Sigstore** issued a short-lived certificate
4. The commit was signed → Cryptographic signature attached to commit
5. The signature was pushed → Verifiable by anyone using public keys

This 30-second authentication protects your code, your team, and your customers. Plus, it triggered a complete OpenShift Pipelines workflow with security scanning and automated deployment!
====

image::tekton-dev-17.png[link=self, window=_blank]

== What You Just Accomplished

Congratulations! You've just experienced the power of OpenShift Pipelines development with RHADS:

=== Time Savings
* **Traditional OpenShift Pipelines setup**: 3-4 weeks of Kubernetes and Tekton configuration
* **RHADS OpenShift Pipelines approach**: Less than 5 minutes of self-service

=== OpenShift Pipelines Security by Default

Your application includes:

* Automated container vulnerability scanning
* Image signing and verification with OpenShift Pipelines
* Tekton pipeline security enforcement
* Kubernetes-native security policies

=== Zero Platform Overhead

Everything was created automatically:

* GitLab repositories with Kubernetes manifests
* Tekton pipelines deployed and configured
* Security tools integrated with OpenShift Pipelines workflows
* OpenShift resources provisioned

== Understanding Your OpenShift Pipelines(Tekton) Pipeline

Now that you've triggered your first pipeline, let's understand what's happening behind the scenes. Your OpenShift Pipelines (Tekton) pipeline is executing several key tasks that ensure security, quality, and deployment automation.

=== Pipeline Tasks Overview

**Task 1: `init`**
Pipeline resources and artifacts required for this pipeline run are initialized. Any reusable components needed downstream are set up.

**Task 2: `clone-repository`**
The source code repository that triggered the pipeline is cloned. The latest code is ensured to be fetched for verification and build.

**Task 3: `verify-commit`**
The Git commit signature is verified using the `gitsign` tool, which is integrated with Red Hat Trusted Application Pipeline (RHTAP). It is ensured by this step that the commit comes from a trusted source and hasn't been tampered with. Details like who signed the commit and whether it passed verification will be shown by clicking on this task in the pipeline UI.

**Task 4: `package`**
The Java source code is built and a Maven artifact — in this case, a Quarkus JAR file — is created.

**Task 5: `build-container`**
A container image for the Quarkus application is built. The following is then performed:

* The image is signed using **Cosign**
* An **SBOM** (Software Bill of Materials) is generated
* The image is attested using **in-toto** for provenance

The image tag corresponds to the Git commit ID that triggered the pipeline.

**Task 6.1: `upload-sboms-to-trustification`**
The SBOM is uploaded to **Red Hat Trusted Profile Analyzer (TPA)** so teams can analyze it for CVEs, vendor advisories, and vulnerabilities. TPA can be accessed at {tpa_url}[Red Hat Trusted Profile Analyzer^] using username `{tpa_user}` and password `{tpa_user_password}`. *SBOMs* on the left menu can be clicked to view results.

**Task 6.2: `update-deployment`**
The new image reference is committed into the GitOps repository. **OpenShift GitOps** (Argo CD) is allowed by this to automatically deploy the new version.

**Task 7.1: `acs-image-check`**
Policy checks on the container image are performed using **Red Hat Advanced Cluster Security (ACS)**. It is ensured that the image doesn't violate any organization-defined security policies.

**Task 7.2: `acs-image-scan`**
The image is scanned for known vulnerabilities and a report is generated. CVEs and risk scores identified in the image will be shown by clicking on this step.

**Task 7.3: `acs-deploy-check`**
The deployment configuration and image are evaluated from a security and compliance perspective. The results are stored in ACS for auditability and enforcement. ACS can also be visited at {acs_url}[Red Hat Advanced Cluster Security^] using `{acs_admin_user}` / `{acs_admin_password}` to explore deeper policy and scan results.

**Task 8.1: `show-sbom`**
The SBOM generated in earlier stages is displayed.

**Task 8.2: `show-summary`**
A high-level summary of the build, verification, signing, and scan results is shown.

---

These aren't just traditional CI steps, as can be seen. Every stage adds a layer of trust, traceability, and security — without slowing down the developer. These steps are not optional or best-effort — they are **enforced** through policy and integrated tooling, giving teams security by default.

=== Brief Note on Pipelines as Code

These pipelines are defined and version-controlled alongside the application code. The CI/CD process is made by this design to be:

* **Transparent** — developers can see exactly how their builds work
* **Consistent** — pipelines follow a shared structure across projects
* **Adaptable** — changes to pipelines are tracked like any other code

For developers at ACME:

* No need to file tickets or wait on DevOps — pipelines are part of the repo.
* Updates to pipeline steps can be proposed via pull requests, just like application code.
* How a change moves from code to container to deployment is easier to understand.

For the ACME platform team:

* Security, compliance, and best practices are automatically enforced by pipeline templates.
* Shared logic updates (like SBOM scanning or image signing) can be reused across all projects.
* Troubleshooting and auditing each change is easier with pipelines stored alongside code.

More autonomy is given to developers by this approach while ensuring the platform team still enforces security and governance by default.

== What You Built: Production Patterns in Action

You just created production infrastructure that most teams spend weeks configuring manually. Let's connect what you experienced to how this works in production environments.

**Pipeline as Code you created:**

Your `.tekton/` directory contains three `PipelineRun` definitions. Each runs as Kubernetes pods in the `openshift-pipelines` namespace. When you pushed your commit, the `on-push.yaml` pipeline triggered automatically via GitLab webhook. No Jenkins server to maintain, no agents to configure—just Kubernetes-native task execution.

**Dev Spaces workspace you used:**

The browser-based IDE isn't just convenient—it's a Kubernetes pod running in your cluster with persistent storage. Your team shares the same base image, same extensions, same tool versions. No more "works on my machine" debugging sessions. The workspace definition lives in `.devfile.yaml` in your repository, version-controlled like everything else.

**Security tooling you triggered:**

Your single `git push` invoked `gitsign` for commit verification, `cosign` for image signing, `syft` for SBOM generation, and ACS for vulnerability scanning. These aren't optional security gates you can bypass—they're pipeline tasks that fail the build if checks don't pass. Your staging and production promotions will verify these signatures before deploying.

**GitOps repository structure:**

The `qrks-tkn-{user}-gitops` repository uses Kustomize overlays: `base/` contains shared manifests, `overlays/dev`, `overlays/stage`, and `overlays/prod` patch environment-specific values. When your pipeline updates `overlays/dev/deployment-patch.yaml` with a new image tag, ArgoCD detects the Git change and reconciles your cluster state automatically. You never run `kubectl apply` manually.

This architecture scales from your single application to hundreds of microservices. Each team owns their pipelines and GitOps repos. Platform team maintains shared task definitions and security policies. Changes to security scanning logic propagate to all projects automatically through the shared task references.

== Next Steps

In the next section, **Staging - Promoting to stage environment**, you'll:

* See your Tekton pipeline execute with OpenShift Pipelines automation
* Understand how security validation works in OpenShift Pipelines
* Experience GitOps deployment to staging environments
* Learn about OpenShift Pipelines monitoring and observability

Your OpenShift Pipelines foundation is now in place - let's see your Tekton pipeline in action!