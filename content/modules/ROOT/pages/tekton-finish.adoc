= OpenShift Pipelines - Summary
:source-highlighter: rouge
:toc: macro
:toclevels: 2

toc::[]

== Module Completion

Congratulations! You've successfully completed the **OpenShift Pipelines (Tekton)** module of the Red Hat Advanced Developer Suite Workshop.

== What You Built

You created a complete CI/CD pipeline using Kubernetes-native tooling—no Jenkins server, no build agents, just containers and Git.

**Application repository:** `qrks-tkn-{user}` with three Tekton `PipelineRun` definitions in `.tekton/` directory. Each pipeline triggers automatically via GitLab webhooks: `on-push.yaml` fires on every `git push`, `on-tag.yaml` fires when you create Git tags, `on-release.yaml` fires when you create GitLab releases. These aren't Jenkins Groovy DSL—they're pure YAML that OpenShift Pipelines executes as Kubernetes pods.

**GitOps repository:** `qrks-tkn-{user}-gitops` with Kustomize overlays for `dev`, `stage`, and `prod` environments. Your pipeline never runs `kubectl apply`—it updates Git, and ArgoCD reconciles cluster state every 3 minutes. Environment promotion is a Git commit, not a deployment script.

**Security artifacts generated:** Every image you built has a cosign signature stored in Quay registry, an SBOM uploaded to Red Hat Trusted Profile Analyzer, and SLSA provenance attestation linking the image to your Git commit. Enterprise Contract validates these artifacts before staging and production promotion. This isn't security theater—these are cryptographic guarantees that your image hasn't been tampered with.

**Development environment:** OpenShift Dev Spaces workspace defined in `.devfile.yaml`. Your entire team can click a link and get identical VSCode environment with same Java version, same Maven settings, same extensions. The workspace is a Kubernetes pod with persistent storage—shutdown your laptop, resume from a different machine, same state.

**What changed from traditional development:**

Traditional approach: 3-4 weeks to get platform team to provision Jenkins agents, configure GitLab webhooks, write custom Groovy pipeline, integrate security scanning tools, set up deployment credentials, configure monitoring.

Tekton approach: 5 minutes to fill a form in Developer Hub. Template generates application code, pipeline definitions, GitOps repository, security scanning integration, and Dev Spaces workspace. Push code, pipeline runs automatically. No tickets, no coordination meetings.

Traditional pipeline: Build runs on dedicated Jenkins agent, image pushed to registry manually, security scanning happens in separate tool with separate credentials, deployment requires VPN and kubectl access to production cluster.

Tekton pipeline: Build runs in ephemeral pod that terminates when done, image automatically signed with cosign, SBOM generated with syft, CVE scanning with ACS—all in the same pipeline. Deployment updates Git; ArgoCD handles cluster reconciliation. No cluster credentials in pipeline.

**Quantified improvements:**

- Pipeline setup: 3-4 weeks → 5 minutes (99.4% reduction)
- Security scanning integration: 2 weeks manual → automatic (included in template)
- Deployment to dev after code change: 30-60 minutes manual → 8 minutes automated
- Staging promotion: 3-5 days coordination → 30 minutes (Git tag triggers pipeline)
- Production deployment: 2-3 weeks → 30 minutes (GitLab release triggers validation + deployment)

== Key Technical Concepts

**Pipelines as Code:** Your `.tekton/on-push.yaml` file is a Kubernetes `PipelineRun` custom resource. When you push code, GitLab webhook sends POST to OpenShift Pipelines Operator. The operator creates Kubernetes pods for each task (`init`, `clone-repository`, `verify-commit`, etc.). Each pod runs a container image specified in the task definition. When the task completes, the pod terminates. No persistent build agents consuming resources 24/7.

**GitOps reconciliation loop:** ArgoCD runs inside your cluster, polling your GitOps repository every 3 minutes. It compares Git state (desired) to cluster state (actual) using `kubectl diff`. When it detects divergence, it applies the manifests from Git. Your pipeline's `update-deployment` task commits new image tags to Git; ArgoCD sees the change and reconciles automatically. This is pull-based deployment—cluster pulls from Git—vs. push-based where CI system pushes to cluster.

**Image signing and verification:** During build, `cosign sign` generates an ECDSA signature of your image digest and stores it in Quay registry as an OCI artifact alongside the image. The signing key lives in Red Hat Trusted Artifact Signer (Sigstore), not in your pipeline. During staging promotion, Enterprise Contract runs `cosign verify` with the public key from `openshift/trusted-keys` ConfigMap. If verification fails, the pipeline terminates before deployment. This prevents deployment of unsigned or tampered images.

**SBOM generation:** The `syft` tool scans your container image filesystem and `pom.xml` to extract all dependencies—Java libraries, OS packages, transitive dependencies. It outputs CycloneDX JSON format listing every component with name, version, and licensing. Enterprise Contract parses this SBOM, extracts package coordinates, and queries Red Hat Security Data API for known CVEs. Any critical vulnerability (CVSS > 9.0) fails the pipeline.

**Kustomize overlays:** Your GitOps repository has `base/` directory with shared Kubernetes manifests (Deployment, Service, Route). The `overlays/dev/`, `overlays/stage/`, and `overlays/prod/` directories contain `deployment-patch.yaml` files that override specific fields like image tag and replica count. Kustomize merges base + overlay to generate final manifests. This eliminates copy-paste duplication across environments.

== When to Use This Approach

**Tekton/OpenShift Pipelines fits when:**

You're building new cloud-native applications on Kubernetes. You want pipelines that run as pods, not dedicated Jenkins agents. Your team knows YAML and kubectl. You're comfortable debugging containers and Kubernetes resources. You value standardization—every project uses the same Tekton task definitions maintained by the platform team.

You're running microservices architectures with dozens or hundreds of services. Each service gets its own `.tekton/` directory with pipeline definitions. Platform team maintains shared task library (`buildah-rhtap.yaml`, `acs-image-scan.yaml`). When platform team improves a task, all projects using it benefit automatically without updating individual pipelines.

You need to scale pipeline execution. Traditional Jenkins agents have capacity limits—if you have 50 build agents and 100 builds queue up, builds wait. Tekton pipelines run as Kubernetes pods. If your cluster has capacity, Kubernetes schedules more pods. If you need more capacity, add worker nodes. No "Jenkins agent offline" debugging.

**Tekton might not fit when:**

You have hundreds of existing Jenkins pipelines with complex Groovy scripting. Migrating Groovy to Tekton YAML would take months. Consider the Jenkins+RHADS approach instead—keep Jenkins, add `rhtap` shared library for security integration.

Your team doesn't have Kubernetes knowledge yet. Debugging failed Tekton tasks requires `kubectl logs`, understanding pod lifecycle, checking PVC storage. If your team is comfortable with Jenkins shell scripts but not `kubectl`, the learning curve is steeper.

You need complex conditional logic or loops in your pipeline. Tekton tasks can run in parallel or sequence, but complex branching requires `when` expressions that are more verbose than Jenkins Groovy. Jenkins Pipelines as Code might be simpler for intricate workflows.

== Next Steps

**Explore the Jenkins module** if your organization has existing Jenkins infrastructure. You'll see how the same RHADS security capabilities (Enterprise Contract, image signing, SBOM generation) integrate into Jenkins workflows using the `rhtap` shared library. Same security guarantees, different execution engine.

**Experiment with the Developer Hub templates** in your own environment. Clone the `tssc-developer-hub-configuration` repository and modify the `scaffolder-templates/quarkus-stssc-template/` to match your organization's standards—different base images, additional pipeline tasks, custom security policies.

**Customize Enterprise Contract policies** to enforce your organization's requirements. The default policy validates image signatures, checks for critical CVEs, and verifies provenance. You can add rules like "reject images with GPL licenses," "require specific base image," or "enforce semantic versioning tags."

**Deep dive into specific technologies:**

- **Tekton Triggers**: Currently GitLab webhooks trigger your pipelines. Tekton Triggers provides EventListeners, TriggerBindings, and TriggerTemplates for more sophisticated event-driven automation (trigger on pull request comments, Slack messages, Jira updates).

- **ArgoCD ApplicationSets**: You manually created ArgoCD Applications for dev, stage, and prod environments. ApplicationSets generate Applications automatically from Git repository structure or cluster selectors, eliminating manual setup for each environment.

- **Cosign keyless signing**: Your workshop used Red Hat Trusted Artifact Signer. Cosign also supports keyless signing with GitHub Actions OIDC tokens—no key management, signature linked to your CI/CD identity provider.

- **Kyverno policy engine**: Enterprise Contract validates images before deployment. Kyverno enforces Kubernetes resource policies at admission time—reject Deployments without resource limits, require specific labels, enforce image pull policies.

== Additional Resources

**Red Hat Documentation:**

* link:https://developers.redhat.com/products/advanced-developer-suite[Red Hat Advanced Developer Suite^]
* link:https://docs.openshift.com/pipelines/[OpenShift Pipelines Documentation^]
* link:https://developers.redhat.com/products/openshift-dev-spaces[OpenShift Dev Spaces^]

**Open Source Projects:**

* link:https://tekton.dev/[Tekton Pipelines^]
* link:https://argoproj.github.io/argo-cd/[ArgoCD GitOps^]
* link:https://backstage.io/[Backstage (Developer Hub foundation)^]

**Community Resources:**

* link:https://www.redhat.com/en/topics/devops[Red Hat DevOps Blog^]
* link:https://developers.redhat.com/[Red Hat Developer Portal^]
* link:https://access.redhat.com/documentation/[Red Hat Product Documentation^]

== Thank You!

Thank you for completing the OpenShift Pipelines module! You've experienced the future of enterprise application development with Red Hat Advanced Developer Suite.

**Continue Your Journey:**

* Explore the **Jenkins** module to see alternative RHADS implementation approaches
* Review the complete workshop resources and additional learning materials
* Plan your organization's implementation strategy based on your experience today

*Your OpenShift Pipelines development transformation starts here!*
